//*****************************************************************************
//
//! @file axi_master_stress_test_cases.c
//!
//! @brief Target one SSRAM memory bank with all AXI masters at the same time.
//!
//! AXI masters on Apollo5a are:
//!   GFX0: GPU source texture (read only)
//!   GFX1: GPU target (read-modify-write when blending)
//!   GFX2: GPU command list (CL) (read only)
//!   DISP: display framebuffer
//!   CM55: CPU access to any other AXI device (read/write)
//!   DMA: APBDMA transfer initiated by a peripheral (read/write)
//!
//! All buffers are located in a single SSRAM bank (128k) using attributes to
//! convince the linker to put the buffer structure in SSRAM and to align to a
//! 128k boundary.
//!
//! DCACHE is disabled as frequent clear/invalidate operations are required and
//! some spurious bugs (particularly writes from CM55 to SSRAM not always
//! going through) would take further work to debug. Disabling DCACHE does not
//! appear to affect throughput.
//!
//! The workloads are run for STRESS_TEST_TRANSFERS iterations, each one
//! followed by a pattern verify.
//!
//! This test launches four workloads to stress the 6 interfaces:
//!   issue_nemagfx_workload:
//!     Ping-pong texture blends between two buffers, clearing the destination
//!     before each blend. The command list for the workload is padded with
//!     NOPs so that GFX2 is thoroughly exercised as well as GFX0 and GFX1.
//!
//!     The flow for the GFX0/1 operations is clear gfx_buffer_B_SSRAM, blend
//!     gfx_buffer_A_SSRAM into gfx_buffer_B_SSRAM, then repeat with A and B
//!     swapped. This set of operations is repeated GFX_BLEND_CYCLES times,
//!     then the NOP padding at the end of the CL is processed. The blend
//!     operation is done in SIMPLE mode in RGBA8888, and with the alpha channel
//!     for the pattern set to 0xFF the GPU will read-modify-write each
//!     pixel at the destination yet will copy exact.
//!
//!     There is no way to verify errors on GFX2 other than a hang or failure to
//!     fully execute the CL. For GFX0 and GFX1, the RGBA8888 pattern in GFX0
//!     at the start of the test should verify exactly when the workload
//!     completes.
//!
//!     This workload is asynchronous, and completion is handled by an interrupt
//!     callback. However it appears that the GPU does not prefetch or
//!     otherwise read from the command list while prior operations on
//!     GFX0 or GFX1 are in flight. Therefore it is likely that the GPU will
//!     never be able to keep all 3 GFX ports busy at the same time.
//!
//!   issue_display_workload:
//!     Send fb_buffer_SSRAM to the display, exercising reads on the DISP master.
//!     This is asynchronous, with completion measured by an interrupt callback.
//!     Verifying the transfer requires measuring the CRC generated by the DC on
//!     sending a window to the display. For now, the CRC for a given buffer
//!     size and pattern is empirically determined by watching the SWO log
//!     messages and plugging the value into the DISP_CRC define.
//!
//!   issue_dma_workload:
//!     Transfers between SSRAM and PSRAM on MSPI0 to generate traffic on the
//!     APBDMA port. At the moment the DMA operation queues a single read or
//!     write transaction asynchronously. To insure that we are generating
//!     both reads and writes, and to verify data integrity, this workload
//!     alternates between writing to PSRAM and reading on each call.
//!
//!   CM55 workload:
//!     To generate read and write traffic on the CM55 port, the CM55 performs a
//!     pattern fill followed by a pattern verify. This is the only workload
//!     that is not asynchronous, and must be executed last to insure that CM55
//!     traffic is concurrent with the other AXI masters.
//!
//! Platform requirements:
//!   apollo5_eb with Peripheral Card 1. apollo5_eb should be in IOX mode 1, and
//!   the Peripheral Card 1 should be jumpered for DSI mode.
//!
//! Results:
//!   Unity will report a pass unless an error is identified in launching a
//!   transfer or in verifying any of the expected patterns.
//!
//!   Periodically the test will print the average time elapsed for each
//!   workload and an overlap measurement for that iteration's workloads.
//!   The overlap is the number of microseconds during which all of the
//!   workloads are simultaneously executing.
//!
//!   A summary log is printed prior to returning the result to Unity displaying
//!   the approximate MB/s for each interface type. This measurement is based
//!   on all traffic types for an interface during the workload. See the header
//!   for the size computation for each type of workload.
//!
//*****************************************************************************

//*****************************************************************************
//
// ${copyright}
//
// This is part of revision ${version} of the AmbiqSuite Development Package.
//
//*****************************************************************************

#include "axi_master_stress_test_cases.h"
#include "nema_error.h"

typedef enum
{
    GPU_BURST_SIZE_16 = 4,
    GPU_BURST_SIZE_32 = 5,
    GPU_BURST_SIZE_64 = 6,
    GPU_BURST_SIZE_128 = 7,
} nemagfx_burst_size_t;

//*****************************************************************************
//
// Buffers
//
//*****************************************************************************

// Texture definitions
img_obj_t gfx_buffer_A_SSRAM = {{0}, TEX_RESX, TEX_RESY, TEX_RESX * 4, 0, NEMA_RGBA8888, 0};
img_obj_t gfx_buffer_B_SSRAM = {{0}, TEX_RESX, TEX_RESY, TEX_RESX * 4, 0, NEMA_RGBA8888, 0};
img_obj_t fb_buffer_SSRAM = {{0}, FB_RESX, FB_RESY, FB_RESX * 4, 0, NEMA_RGBA8888, 0};

// statically allocate SSRAM buffers
struct SSRAMBank_ {
    uint8_t cl[CL_SIZE];
    uint8_t tex_a[TEX_RESX * TEX_RESY * 4];
    uint8_t tex_b[TEX_RESX * TEX_RESY * 4];
    uint8_t fb[FB_RESX * FB_RESY * 4];
    uint8_t dma[DMA_SIZE];
    uint8_t cm55[CM55_SIZE];
} g_sSSRAMBank __attribute__ ((aligned(1024*128))) AM_SHARED_RW;


// patterns
#define PATTERN_RGBA8888_LENGTH 16
uint32_t g_pui32RGBA8888Pattern[PATTERN_RGBA8888_LENGTH] = {
            0xFFFF0000,
            0xFFFF4400,
            0xFFFF8800,
            0xFFFFCC00,
            0xFFEEFF00,
            0xFFAAFF00,
            0xFF66FF00,
            0xFF22FF00,
            0xFF00FF22,
            0xFF00FF66,
            0xFF00FFAA,
            0xFF00FFEE,
            0xFF00CCFF,
            0xFF0088FF,
            0xFF0044FF,
            0xFF0000FF
};

#define PATTERN_MEM_LENGTH 16
uint32_t g_pui32MemPattern[PATTERN_MEM_LENGTH] = {
            0xF00F5AA5,
            0xA5F00F5A,
            0x5AA5F00F,
            0x0F5AA5F0,
            0x55555555,
            0xAAAAAAAA,
            0xCCCCCCCC,
            0x33333333,
            0xA5A5A5A5,
            0x5A5A5A5A,
            0xC3C3C3C3,
            0x3C3C3C3C,
            0x5A5A5A5A,
            0xA5A5A5A5,
            0x3C3C3C3C,
            0xC3C3C3C3
};

//*****************************************************************************
//
// Globals
//
//*****************************************************************************
bool g_bCLCreated = false;

volatile float g_fGFXStartTime = 0.f;
volatile float g_fGFXStopTime = 0.f;
volatile bool g_bGFXDone = false;
volatile float g_fDispStartTime = 0.f;
volatile float g_fDispStopTime = 0.f;
volatile bool g_bDispDone = false;
volatile float g_fDMAStartTime = 0.f;
volatile float g_fDMAStopTime = 0.f;
volatile bool g_bDMADone = false;
volatile bool g_bDMARead = false;
volatile int g_iIssuedCLID = -1;
nema_cmdlist_t sCL;

extern void *g_pPsramHandle; // from nemagfx_test_common.c

//*****************************************************************************
//
// MSPI specific
//
///*****************************************************************************
AM_SHARED_RW uint32_t        ui32DMATCBBuffer[2560];
void            *g_pPsramHandle;
void            *g_pMSPIPsramHandle;

am_devices_mspi_psram_config_t g_sMspiPsramConfig =
{
#ifdef APOLLO5_FPGA
    .eDeviceConfig            = AM_HAL_MSPI_FLASH_OCTAL_DDR_CE0,
#else
    .eDeviceConfig            = AM_HAL_MSPI_FLASH_HEX_DDR_CE0,
#endif
    // 96MHz MSPI SCLK w/ DDR == 192MHz Mtransfers/s
    .eClockFreq               = AM_HAL_MSPI_CLK_192MHZ,
    .ui32NBTxnBufLength       = sizeof(ui32DMATCBBuffer) / sizeof(uint32_t),
    .pNBTxnBuf                = ui32DMATCBBuffer,
    .ui32ScramblingStartAddr  = 0,
    .ui32ScramblingEndAddr    = 0,
};

am_hal_mpu_region_config_t sMPUCfg =
{
    .ui32RegionNumber = 6,
    .ui32BaseAddress = (uint32_t)ui32DMATCBBuffer,
    .eShareable = NON_SHARE,
    .eAccessPermission = RW_NONPRIV,
    .bExecuteNever = true,
    .ui32LimitAddress = (uint32_t)ui32DMATCBBuffer + sizeof(ui32DMATCBBuffer) - 1,
    .ui32AttrIndex = 0,
    .bEnable = true,
};
am_hal_mpu_attr_t sMPUAttr =
{
    .ui8AttrIndex = 0,
    .bNormalMem = true,
    .sOuterAttr = {
                    .bNonTransient = false,
                    .bWriteBack = true,
                    .bReadAllocate = false,
                    .bWriteAllocate = false
                  },
    .sInnerAttr = {
                    .bNonTransient = false,
                    .bWriteBack = true,
                    .bReadAllocate = false,
                    .bWriteAllocate = false
                  },
    .eDeviceAttr = 0,
};

//! MSPI interrupts.
static const IRQn_Type MspiInterrupts[] =
{
    MSPI0_IRQn,
    MSPI1_IRQn,
    MSPI2_IRQn,
};

//
// Take over the interrupt handler for whichever MSPI we're using.
//
#define psram_mspi_isr                                                          \
    am_mspi_isr1(MSPI_PSRAM_MODULE)
#define am_mspi_isr1(n)                                                        \
    am_mspi_isr(n)
#define am_mspi_isr(n)                                                         \
    am_mspi ## n ## _isr

//*****************************************************************************
//
//  MSPI ISRs.
//
//*****************************************************************************
void psram_mspi_isr(void)
{
   uint32_t      ui32Status;

   am_hal_mspi_interrupt_status_get(g_pMSPIPsramHandle, &ui32Status, false);

   am_hal_mspi_interrupt_clear(g_pMSPIPsramHandle, ui32Status);

   am_hal_mspi_interrupt_service(g_pMSPIPsramHandle, ui32Status);
}

//*****************************************************************************
//
//  Display init with centering of the FB
//
// based on tests/testcases/apollo5/nemagfx_tests/common/nemagfx_test_common.c
//
//*****************************************************************************
uint32_t
dc_common_interface(uint16_t ui16ResX,uint16_t ui16ResY)
{
    uint16_t ui16MinX, ui16MinY;
    nemadc_initial_config_t sDCConfig;
    am_devices_dc_xspi_raydium_config_t sDisplayPanelConfig;
    uint32_t ui32MipiCfg = MIPICFG_16RGB888_OPT0;    //!< default config
    //
    // Set the display region to center
    //
    if (ui16ResX < g_sDispCfg.ui16ResX)
    {
        sDisplayPanelConfig.ui16ResX = ui16ResX;
    }
    else
    {
        sDisplayPanelConfig.ui16ResX = g_sDispCfg.ui16ResX;
    }
    ui16MinX = (g_sDispCfg.ui16ResX - sDisplayPanelConfig.ui16ResX) >> 1;
    ui16MinX = (ui16MinX >> 1) << 1;

    if (ui16ResY < g_sDispCfg.ui16ResY)
    {
        sDisplayPanelConfig.ui16ResY = ui16ResY;
    }
    else
    {
        sDisplayPanelConfig.ui16ResY = g_sDispCfg.ui16ResY;
    }
    ui16MinY = (g_sDispCfg.ui16ResY - sDisplayPanelConfig.ui16ResY) >> 1;
    ui16MinY = (ui16MinY >> 1) << 1;

    g_sDispCfg.eTEType = DISP_TE_DISABLE;
    sDCConfig.ui16ResX = sDisplayPanelConfig.ui16ResX;
    sDCConfig.ui16ResY = sDisplayPanelConfig.ui16ResY;
    sDCConfig.bTEEnable = (g_sDispCfg.eTEType == DISP_TE_DC);
    sDisplayPanelConfig.ui16MinX = ui16MinX + g_sDispCfg.ui16Offset;
    sDisplayPanelConfig.ui16MinY = ui16MinY;
    sDisplayPanelConfig.bTEEnable = (g_sDispCfg.eTEType != DISP_TE_DISABLE);
    sDisplayPanelConfig.bFlip = g_sDispCfg.bFlip;

    am_bsp_disp_pins_enable();

    if (g_sDispCfg.eInterface == DISP_IF_DSI)
    {
        //
        // VDD18 control callback function
        //
        am_hal_dsi_register_external_vdd18_callback(am_bsp_external_vdd18_switch);
        //
        // Enable DSI power and configure DSI clock.
        //
        am_hal_dsi_init();
    }
    else
    {
        am_hal_clkgen_control(AM_HAL_CLKGEN_CONTROL_DISPCLKSEL_HFRC96, NULL);
        am_hal_clkgen_control(AM_HAL_CLKGEN_CONTROL_DCCLK_ENABLE, NULL);
    }
    am_hal_pwrctrl_periph_enable(AM_HAL_PWRCTRL_PERIPH_DISP);

    //
    //Initialize NemaDC
    //
    if (nemadc_init() != 0)
    {
        return -2;
    }

    if (g_sDispCfg.eInterface == DISP_IF_DSI)
    {
        uint8_t ui8LanesNum = g_sDispCfg.ui8NumLanes;
        uint8_t ui8DbiWidth = g_sDispCfg.eDbiWidth;
        uint32_t ui32FreqTrim = g_sDispCfg.eDsiFreq;
        pixel_format_t eFormat = FMT_RGB888;
        if (am_hal_dsi_para_config(ui8LanesNum, ui8DbiWidth, ui32FreqTrim, false) != 0)
        {
            return -3;
        }
        switch (eFormat)
        {
            case FMT_RGB888:
                if (ui8DbiWidth == 16)
                {
                    ui32MipiCfg = MIPICFG_16RGB888_OPT0;
                }
                if (ui8DbiWidth == 8)
                {
                    ui32MipiCfg = MIPICFG_8RGB888_OPT0;
                }
                break;

            case FMT_RGB565:
                if (ui8DbiWidth == 16)
                {
                    ui32MipiCfg = MIPICFG_16RGB565_OPT0;
                }
                if (ui8DbiWidth == 8)
                {
                    ui32MipiCfg = MIPICFG_8RGB565_OPT0;
                }
                break;

            default:
                //
                // invalid color component index
                //
                return -3;
        }
    }

    //
    // Initialize the display
    //
    switch (g_sDispCfg.eInterface)
    {
        case DISP_IF_SPI4:
            am_devices_dc_xspi_raydium_hardware_reset();
            sDCConfig.eInterface = DISP_INTERFACE_SPI4;
            sDCConfig.ui32PixelFormat = MIPICFG_1RGB888_OPT0;
            sDisplayPanelConfig.ui32PixelFormat = sDCConfig.ui32PixelFormat;
            nemadc_configure(&sDCConfig);
            am_devices_dc_xspi_raydium_init(&sDisplayPanelConfig);
            break;
        case DISP_IF_DSPI:
            am_devices_dc_xspi_raydium_hardware_reset();
            sDCConfig.eInterface = DISP_INTERFACE_DSPI;
            sDCConfig.ui32PixelFormat = MIPICFG_2RGB888_OPT0;
            sDisplayPanelConfig.ui32PixelFormat = sDCConfig.ui32PixelFormat;
            nemadc_configure(&sDCConfig);
            am_devices_dc_xspi_raydium_init(&sDisplayPanelConfig);

            break;
        case DISP_IF_QSPI:
            am_devices_dc_xspi_raydium_hardware_reset();
            sDCConfig.eInterface = DISP_INTERFACE_QSPI;
            sDCConfig.ui32PixelFormat = MIPICFG_4RGB888_OPT0;
            sDisplayPanelConfig.ui32PixelFormat = sDCConfig.ui32PixelFormat;
            nemadc_configure(&sDCConfig);
            am_devices_dc_xspi_raydium_init(&sDisplayPanelConfig);
            break;
        case DISP_IF_DSI:
            am_devices_dc_dsi_raydium_hardware_reset();
            sDCConfig.eInterface = DISP_INTERFACE_DBIDSI;
            sDCConfig.ui32PixelFormat = ui32MipiCfg;
            sDisplayPanelConfig.ui32PixelFormat = ui32MipiCfg;
            nemadc_configure(&sDCConfig);
            am_devices_dc_dsi_raydium_init(((am_devices_dc_dsi_raydium_config_t *) &sDisplayPanelConfig));
            break;
        default:
            ; //NOP
    }

    return 0;
}

//------------------------------------------------------------------------
//
//  Flush cache within a range
//
// addr: pointer to the memory to flush
// size: size of memory region in bytes
//
//------------------------------------------------------------------------
static inline void
flush_cache_range(void* addr, uint32_t size)
{
#if USE_DCACHE
    am_hal_cachectrl_range_t Range;
    Range.ui32Size = size;
    Range.ui32StartAddr = (uint32_t)addr;
    am_hal_cachectrl_dcache_invalidate(&Range, true);
#endif
}

//------------------------------------------------------------------------
//
//  Set GPU fb and texture burst sizes in the current command list
//
// fb_burst_size: one-hot framebuffer read burst size. See enums in nemagfx_burst_size_t
// tex_burst_size: one-hot texture read burst size. See enums in nemagfx_burst_size_t
//
//------------------------------------------------------------------------
void
set_nema_burst_size(nemagfx_burst_size_t fb_burst_size, nemagfx_burst_size_t tex_burst_size)
{
    uint32_t burst_size_reg_val = 0x0UL|((fb_burst_size)<<4)|(tex_burst_size);
    nema_cl_add_cmd(NEMA_BURST_SIZE, burst_size_reg_val);
}

//------------------------------------------------------------------------
//
//  Set the CPU and GPU performance mode
//
// mcu_mode: CPU performance mode. See am_hal_pwrctrl_mcu_mode_e for options
// gpu_mode: GPU performance mode. See am_hal_pwrctrl_gpu_mode_e for options
//
//------------------------------------------------------------------------
void
set_perf_mode(am_hal_pwrctrl_mcu_mode_e mcu_mode, am_hal_pwrctrl_gpu_mode_e gpu_mode)
{
    uint32_t ui32Status = am_hal_pwrctrl_mcu_mode_select(mcu_mode);
    if ( AM_HAL_STATUS_SUCCESS != ui32Status)
    {
        am_util_stdio_printf("CPU change power mode failed!\n");
        while(1){};
    }

    // disable GPU before power mode change
    am_hal_pwrctrl_periph_disable(AM_HAL_PWRCTRL_PERIPH_GFX);

    am_hal_pwrctrl_gpu_mode_e current_mode;
    am_hal_pwrctrl_gpu_mode_select(gpu_mode);
    am_hal_pwrctrl_gpu_mode_status(&current_mode);

    if(gpu_mode != current_mode)
    {
        am_util_stdio_printf("gpu switch power mode failed!\n");
        while(1){};
    }
    // reenable and reinit GPU after power mode change
    am_hal_pwrctrl_periph_enable(AM_HAL_PWRCTRL_PERIPH_GFX);
    nema_init();
}

//*****************************************************************************
//
//  Fill a buffer with a predefined pattern
//
// *buffer - pattern destination buffer
// len - buffer length in bytes
// *pattern - pattern source buffer of uint32_t dwords
// pattern_length - length of pattern in uint32_t size dwords
//
// NOTE: changing the fill pattern will affect the expected display controller
// CRC. If this happens (and you trust your HW!) update the CRC in the header
// from the DC_CRC in the SWO logs.
//
//*****************************************************************************
void
fill_pattern(uint32_t* buffer, uint32_t len, uint32_t* pattern, uint32_t pattern_length)
{
    uint32_t* src_buf_index = buffer;
    while((void*)src_buf_index < ((void*)buffer + len))
    {
        memcpy(src_buf_index, pattern, pattern_length * sizeof(uint32_t));
        src_buf_index += pattern_length;
    }
    flush_cache_range((void*)buffer, len);
}

//*****************************************************************************
//
//  Verify a filled buffer
//
// *buffer - buffer to verify
// len - buffer length in bytes
// *pattern - pattern source buffer of uint32_t dwords
// pattern_length - length of pattern in uint32_t size dwords
// pattern_mismatch_msg - string to log when the pattern does not match
//
//*****************************************************************************
void
verify_pattern(uint32_t* buffer, uint32_t len, uint32_t* pattern, uint32_t pattern_length, char* pattern_mismatch_msg)
{
    uint32_t* src_buf_index = buffer;
    uint32_t pattern_index;
    while((void*)src_buf_index < ((void*)buffer + len))
    {
        for(pattern_index=0;pattern_index < pattern_length; pattern_index++)
        {
            if(pattern[pattern_index] != src_buf_index[pattern_index])
            {
                char errmsg[80];
                snprintf(errmsg, 80, "%s at 0x%08x expected 0x%08x got 0x%08x",
                    pattern_mismatch_msg, (unsigned int)&src_buf_index[pattern_index],
                    (unsigned int)pattern[pattern_index], (unsigned int)src_buf_index[pattern_index]);
                TEST_FAIL_MESSAGE(errmsg);
            }
        }
        src_buf_index += pattern_length;
    }
}

//*****************************************************************************
//
//  Log display transfer completion time
//
//*****************************************************************************
void disp_vsync_callback(void * pCallbackCtxt, uint32_t status)
{
    if(!g_bDispDone)
    {
        g_fDispStopTime = nema_get_time();
        g_bDispDone = true;
    }
}

//*****************************************************************************
//
//  Log GPU command list completion time
//
//*****************************************************************************
void gfx_callback(volatile int last_clid)
{
    if(!g_bGFXDone && (last_clid == g_iIssuedCLID))
    {
        g_fGFXStopTime = nema_get_time();
        g_bGFXDone = true;
    }
}

//*****************************************************************************
//
//  Log completion time when the DMA transfer completes
//
//*****************************************************************************
void
dma_callback(void *pCallbackCtxt, uint32_t status)
{
    if(!g_bDMADone)
    {
        g_fDMAStopTime = nema_get_time();
        g_bDMADone = true;
    }
}

//------------------------------------------------------------------------
//
//  Prepare GPU command list
//
// *cl - Target command list pointer
//
//------------------------------------------------------------------------
void
setup_command_list(nema_cmdlist_t *cl)
{
    nema_buffer_t clbuffer;

    clbuffer.base_phys = (uintptr_t)g_sSSRAMBank.cl;
    clbuffer.base_virt = (void*)g_sSSRAMBank.cl;
    clbuffer.size = CL_SIZE;
    clbuffer.fd = 0;

    // create a CL in the assigned memory
    *cl = nema_cl_create_prealloc(&clbuffer);
    g_bCLCreated = true;
    TEST_ASSERT_EQUAL_UINT32_MESSAGE(nema_get_error(), NEMA_ERR_NO_ERROR, "NEMA error in prealloc");

    nema_cl_bind(cl);
    set_nema_burst_size(FB_BURST_SIZE, TEX_BURST_SIZE);

    for(int i=0; i<GFX_BLEND_CYCLES; i++)
    {
        // Copy from A->B using blitter
        nema_bind_dst_tex(gfx_buffer_B_SSRAM.bo.base_phys,
                            gfx_buffer_B_SSRAM.w,
                            gfx_buffer_B_SSRAM.h,
                            gfx_buffer_B_SSRAM.format,
                            gfx_buffer_B_SSRAM.stride);
        nema_bind_src_tex(gfx_buffer_A_SSRAM.bo.base_phys,
                            gfx_buffer_A_SSRAM.w,
                            gfx_buffer_A_SSRAM.h,
                            gfx_buffer_A_SSRAM.format,
                            gfx_buffer_A_SSRAM.stride,
                            NEMA_FILTER_PS);
        nema_clear(0x00000000); // clear destination w/ zeroed alpha
        nema_set_clip(0, 0, TEX_RESX, TEX_RESY);
        nema_set_blend_blit(NEMA_BL_SIMPLE);
        nema_blit(0, 0);

        nema_bind_dst_tex(gfx_buffer_A_SSRAM.bo.base_phys,
                            gfx_buffer_A_SSRAM.w,
                            gfx_buffer_A_SSRAM.h,
                            gfx_buffer_A_SSRAM.format,
                            gfx_buffer_A_SSRAM.stride);
        nema_bind_src_tex(gfx_buffer_B_SSRAM.bo.base_phys,
                            gfx_buffer_B_SSRAM.w,
                            gfx_buffer_B_SSRAM.h,
                            gfx_buffer_B_SSRAM.format,
                            gfx_buffer_B_SSRAM.stride,
                            NEMA_FILTER_PS);
        nema_clear(0x00000000); // clear destination w/ zeroed alpha
        nema_set_clip(0, 0, TEX_RESX, TEX_RESY);
        nema_set_blend_blit(NEMA_BL_SIMPLE);
        nema_blit(0, 0);
    }
    // fill remainder of CL with NOPs
    // NOPs are about 8 bytes long
    uint32_t nops=0;
    for(int i=0;i<(CL_SIZE/8); i++)
    {
        if(nema_cl_almost_full(cl))
            break;
        nema_cl_add_cmd(CL_NOP, 0x0);
        TEST_ASSERT_EQUAL_UINT32_MESSAGE(nema_get_error(), NEMA_ERR_NO_ERROR, "NEMA error in NOP fill");
        nops++;
    }
    flush_cache_range((void*)cl->bo.base_phys, cl->bo.size);

    nema_cl_unbind();
}

//*****************************************************************************
//
//  Optional Global setup/tear-down.
//
// globalSetUp() will get called before the test group starts, and
// globalTearDown() will get called after it ends. These won't be necessary for
// every test.
//
//*****************************************************************************
void
globalSetUp(void)
{

#if !USE_DCACHE
    am_hal_cachectrl_dcache_disable(); // disabled due to weird interaction between display and CM55 workloads
#endif
    set_perf_mode(AM_HAL_PWRCTRL_MCU_MODE_HIGH_PERFORMANCE, AM_HAL_PWRCTRL_GPU_MODE_HIGH_PERFORMANCE);

    //
    // Global interrupt enable
    //
    am_hal_interrupt_master_enable();

    am_hal_pwrctrl_periph_enable(AM_HAL_PWRCTRL_PERIPH_GFX);

	//
    // Set up the attributes.
    //
    am_hal_mpu_attr_configure(&sMPUAttr, 1);
    //
    // Clear the MPU regions.
    //
    am_hal_mpu_region_clear();
    //
    // Set up the regions.
    //
    am_hal_mpu_region_configure(&sMPUCfg, 1);
    //
    // Invalidate and clear DCACHE, this is required by CM55 TRF.
    //
    am_hal_cachectrl_dcache_invalidate(NULL, true);
    //
    // MPU enable
    //
    am_hal_mpu_enable(true, true);

    //
    // Initialize NemaGFX
    //
    if(nema_init() != 0)
    {
        am_util_stdio_printf("GPU init failed!\n");
    }

    uint32_t ui32Status;

    //
    // Run MSPI DDR timing scan
    //
    am_devices_mspi_psram_ddr_timing_config_t MSPIDdrTimingConfig;
    am_util_debug_printf("Starting MSPI DDR Timing Scan: \n");
    if ( AM_DEVICES_MSPI_PSRAM_STATUS_SUCCESS == am_devices_mspi_psram_aps25616n_ddr_init_timing_check(MSPI_PSRAM_MODULE, &g_sMspiPsramConfig, &MSPIDdrTimingConfig) )
    {
        am_util_debug_printf("==== Scan Result: RXDQSDELAY0 = %d \n", MSPIDdrTimingConfig.ui32Rxdqsdelay);
    }
    else
    {
        am_util_debug_printf("==== Scan Result: Failed, no valid setting.  \n");
    }

    //
    // Configure the MSPI and PSRAM Device.
    //
    ui32Status = am_devices_mspi_psram_aps25616n_ddr_init(MSPI_PSRAM_MODULE, &g_sMspiPsramConfig, &g_pPsramHandle, &g_pMSPIPsramHandle);
    if (AM_DEVICES_MSPI_PSRAM_STATUS_SUCCESS != ui32Status)
    {
        am_util_stdio_printf("Failed to configure the MSPI and PSRAM Device correctly!\n");
    }
    NVIC_SetPriority(MspiInterrupts[MSPI_PSRAM_MODULE], PSRAM_ISR_PRIORITY);
    NVIC_EnableIRQ(MspiInterrupts[MSPI_PSRAM_MODULE]);

    //
    // Apply DDR timing setting
    //
    ui32Status = am_devices_mspi_psram_aps25616n_apply_ddr_timing(g_pPsramHandle, &MSPIDdrTimingConfig);
    if (AM_HAL_STATUS_SUCCESS != ui32Status)
    {
        am_util_stdio_printf("Failed to apply the timming scan parameter!\n");
    }

    dc_common_interface(FB_RESX,FB_RESY);
}

void
globalTearDown(void)
{
    uint32_t ui32Status;

    //
    // Need to make sure all pending XIPMM transactions are flushed
    //
    am_hal_cachectrl_dcache_invalidate(NULL, true);

    ui32Status = am_devices_mspi_psram_aps25616n_ddr_disable_xip(g_pPsramHandle);
    if (AM_DEVICES_MSPI_PSRAM_STATUS_SUCCESS != ui32Status)
    {
        am_util_stdio_printf("Failed to disable XIP mode in the MSPI!\n");
    }

    ui32Status = am_devices_mspi_psram_aps25616n_ddr_deinit(g_pPsramHandle);
    if (AM_DEVICES_MSPI_PSRAM_STATUS_SUCCESS != ui32Status)
    {
        am_util_stdio_printf("Failed to deinit the MSPI and PSRAM Device correctly!\n");
    }
}


//*****************************************************************************
//
//  Optional setup/tear-down functions.
//
// These will be called before and after each test function listed below.
//
//*****************************************************************************
void
setUp(void)
{

    nemagfx_set_interrupt_callback(gfx_callback);

    // initialize gfx and dc buffers
    gfx_buffer_A_SSRAM.bo.base_phys = (uintptr_t)g_sSSRAMBank.tex_a;
    gfx_buffer_A_SSRAM.bo.base_virt = (void*)gfx_buffer_A_SSRAM.bo.base_phys;
    gfx_buffer_A_SSRAM.bo.size = gfx_buffer_A_SSRAM.w * gfx_buffer_A_SSRAM.h * 4;
    gfx_buffer_B_SSRAM.bo.base_phys = (uintptr_t)g_sSSRAMBank.tex_b;
    gfx_buffer_B_SSRAM.bo.base_virt = (void*)gfx_buffer_B_SSRAM.bo.base_phys;
    gfx_buffer_B_SSRAM.bo.size = gfx_buffer_B_SSRAM.w * gfx_buffer_B_SSRAM.h * 4;
    fb_buffer_SSRAM.bo.base_phys = (uintptr_t)g_sSSRAMBank.fb;
    fb_buffer_SSRAM.bo.base_virt = (void*)fb_buffer_SSRAM.bo.base_phys;
    fb_buffer_SSRAM.bo.size = fb_buffer_SSRAM.w * fb_buffer_SSRAM.h * 4;
    // prefill the source buffer on the first iteration
    fill_pattern(gfx_buffer_A_SSRAM.bo.base_virt, gfx_buffer_A_SSRAM.bo.size, g_pui32RGBA8888Pattern, PATTERN_RGBA8888_LENGTH);
    fill_pattern(fb_buffer_SSRAM.bo.base_virt, fb_buffer_SSRAM.bo.size,  g_pui32RGBA8888Pattern, PATTERN_RGBA8888_LENGTH);
    fill_pattern((uint32_t*)g_sSSRAMBank.dma, DMA_SIZE, g_pui32MemPattern, PATTERN_MEM_LENGTH);

    // clear the CM55 buffer
    memset(g_sSSRAMBank.cm55, 0, CM55_SIZE);
    flush_cache_range((void*)g_sSSRAMBank.cm55, CM55_SIZE);

    setup_command_list(&sCL);

    // DC setup
    //
    // Assign a fixed value to display type.
    //

    nemadc_set_vsync_interrupt_callback(disp_vsync_callback, NULL);

    //
    // send layer 0 to display via NemaDC
    //
    nemadc_layer_t layer0 = {0};
    layer0.resx          = FB_RESX;
    layer0.resy          = FB_RESY;
    layer0.buscfg        = 0;
    layer0.format        = NEMADC_RGBA8888;
    layer0.blendmode     = NEMADC_BL_SRC;
    layer0.stride        = layer0.resx * 4;
    layer0.startx        = 0;
    layer0.starty        = 0;
    layer0.sizex         = layer0.resx;
    layer0.sizey         = layer0.resy;
    layer0.alpha         = 0xff;
    layer0.flipx_en      = 0;
    layer0.flipy_en      = 0;
    layer0.baseaddr_virt = fb_buffer_SSRAM.bo.base_virt;
    layer0.baseaddr_phys = fb_buffer_SSRAM.bo.base_phys;

    nemadc_set_layer(0, &layer0); // This function includes layer enable.
}

void
tearDown(void)
{
}


//*****************************************************************************
//
//  Start DMA traffic, either a read or write to MSPI from SSRAM
//
// The global flag g_bDMARead is used to determine whether or not we are reading
// or writing. We alternate on each call so that we write first then read back to
// the same buffer in SSRAM. The caller is responsible for clearing the buffer
// before reading to insure that an aborted read doesn't pass the pattern verify
//
//*****************************************************************************
void
issue_dma_workload()
{
    uint32_t dma_stat;
    static uint32_t dummy_context;
    g_bDMADone = false;
#if USE_DCACHE
    AM_CRITICAL_BEGIN // guard was required when dcache enabled - prob because the TCB is in SSRAM
#endif
    if(g_bDMARead)
    {
        dma_stat = am_devices_mspi_psram_aps25616n_ddr_nonblocking_read(g_pPsramHandle,
            g_sSSRAMBank.dma,
            0x0,
            DMA_SIZE,
            dma_callback,
            (void*)&dummy_context);
        g_bDMARead = false;
    }
    else
    {
        dma_stat = am_devices_mspi_psram_aps25616n_ddr_nonblocking_write(g_pPsramHandle,
            g_sSSRAMBank.dma,
            0x0,
            DMA_SIZE,
            dma_callback,
            (void*)&dummy_context);
        g_bDMARead = true;
    }
    g_fDMAStartTime = nema_get_time();
#if USE_DCACHE
    AM_CRITICAL_END
#endif
    TEST_ASSERT_EQUAL_UINT32_MESSAGE(dma_stat, AM_DEVICES_MSPI_PSRAM_STATUS_SUCCESS, "DMA error during DMA transfer");
}

//*****************************************************************************
//
//  Send the display framebuffer to the display
//
//*****************************************************************************
void
issue_display_workload()
{
    g_bDispDone = false;
    nemadc_transfer_frame_prepare(g_sDispCfg.eTEType != DISP_TE_DISABLE);
    if(g_sDispCfg.eTEType == DISP_TE_DISABLE)
    {
        //
        //It's necessary to launch frame manually when TE is disabled.
        //
        nemadc_transfer_frame_launch();
        g_fDispStartTime = nema_get_time();
    }
}

//------------------------------------------------------------------------
//
//  Launch nemagfx workload command list
//
//
// *cl - Target command list pointer
//
//------------------------------------------------------------------------
void
issue_nemagfx_workload(nema_cmdlist_t *cl)
{
    g_bGFXDone = false;
    g_fGFXStartTime = nema_get_time();
    nema_cl_submit(cl);
    g_iIssuedCLID = cl->submission_id;
    TEST_ASSERT_EQUAL_UINT32_MESSAGE(nema_get_error(), NEMA_ERR_NO_ERROR, "NEMA error in submit");
}

//*****************************************************************************
//
//! @brief Stress the AXI master ports
//!
//! This test reports measurements to SWO and not pass/fail.
//!
//! @return bTestPass (always true)
//
//*****************************************************************************
bool
axi_master_stress_test_cases(void)
{
    bool bTestPass = true;
    uint32_t completed_transfers = 0;
    uint32_t nemadc_crc;
    float cm55_start_time;
    float cm55_stop_time;
    float cm55_time_spent = 0;
    float disp_time_spent = 0;
    float gfx_time_spent = 0;
    float dma_time_spent = 0;
    float overlap_total = 0;
    float stop_min, start_max, overlap;
    float gfx_avg, disp_avg, dma_avg, cm55_avg;

    am_util_stdio_printf("\n AXI master stress test:\n\n");

    while(completed_transfers < STRESS_TEST_TRANSFERS)
    {
        // prep
        if(g_bDMARead)
        {
            // If we're reading back from PSRAM, clear the buffer first so we can
            // properly verify the written contents later
            memset(g_sSSRAMBank.dma, 0, DMA_SIZE);
            flush_cache_range((void*)g_sSSRAMBank.dma, DMA_SIZE);
        }

        // issue
        issue_nemagfx_workload(&sCL);
        issue_dma_workload();
        issue_display_workload();

        // CM55 pattern is a fill plus flush
        cm55_start_time = nema_get_time();
        fill_pattern((uint32_t*)g_sSSRAMBank.cm55, CM55_SIZE, g_pui32MemPattern, PATTERN_MEM_LENGTH);
        verify_pattern((uint32_t*)g_sSSRAMBank.cm55, CM55_SIZE, g_pui32MemPattern, PATTERN_MEM_LENGTH, "CM55");
        cm55_stop_time = nema_get_time();

        // wait for async workloads
        while(!g_bGFXDone || !g_bDispDone || !g_bDMADone)
        {
        }

        // verify
        nemadc_crc = nemadc_reg_read(NEMADC_REG_CRC);
        TEST_ASSERT_EQUAL_UINT32_MESSAGE(nemadc_crc, DISP_CRC, "Display CRC mismatch");

        verify_pattern(gfx_buffer_A_SSRAM.bo.base_virt,
            gfx_buffer_A_SSRAM.bo.size,
            g_pui32RGBA8888Pattern,
            PATTERN_RGBA8888_LENGTH,
            "GFX");
        verify_pattern((uint32_t*)g_sSSRAMBank.dma,
            DMA_SIZE,
            g_pui32MemPattern,
            PATTERN_MEM_LENGTH,
            "DMA");

        completed_transfers++;

        // Calculate time spent and the transfer overlap interval
        gfx_time_spent += g_fGFXStopTime - g_fGFXStartTime;
        dma_time_spent += g_fDMAStopTime - g_fDMAStartTime;
        disp_time_spent += g_fDispStopTime - g_fDispStartTime;
        cm55_time_spent += cm55_stop_time - cm55_start_time;

        start_max = g_fGFXStartTime;
        stop_min = g_fGFXStopTime;

        if(g_fDMAStartTime > start_max)
        {
            start_max = g_fDMAStartTime;
        }
        if(g_fDispStartTime > start_max)
        {
            start_max = g_fDispStartTime;
        }
        if(cm55_start_time > start_max)
        {
            start_max = cm55_start_time;
        }
        if(g_fDMAStopTime < stop_min)
        {
            stop_min = g_fDMAStopTime;
        }
        if(g_fDispStopTime < stop_min)
        {
            stop_min = g_fDispStopTime;
        }
        if(cm55_stop_time < stop_min)
        {
            stop_min = cm55_stop_time;
        }

        overlap = stop_min - start_max;
        if(overlap < 0.f){
            overlap = 0;
        }

        overlap_total += overlap;

        // print log message every LOG_INTERVAL transfers
        if(((completed_transfers % LOG_INTERVAL) == 0) || (completed_transfers >= STRESS_TEST_TRANSFERS))
        {
            disp_avg = (disp_time_spent / completed_transfers);
            dma_avg = (dma_time_spent / completed_transfers);
            gfx_avg = (gfx_time_spent / completed_transfers);
            cm55_avg = (cm55_time_spent / completed_transfers);

            am_util_stdio_printf("\n%6d:  DMA avg %4.3f us  GFX avg %4.3f us  CM55 avg %4.3f us  DISP avg: %4.3f us  overlap: %4.3f us  DC_CRC 0x%08X\n",
                completed_transfers,
                dma_avg * 1000000.0,
                gfx_avg * 1000000.0,
                cm55_avg * 1000000.0,
                disp_avg * 1000000.0,
                overlap * 1000000.0,
                nemadc_crc);
        }
    }

    // Test summary log
    am_util_stdio_printf("\nDMA: %.2f MB/s  GFX: %.2f MB/s  CM55: %.2f MB/s  DISP: %.2f MB/s  overlap avg: %4.3f us\n",
            DMA_SIZE / (dma_avg * (1024.0*1024.0)),
            GFX_BYTES_PER_ISSUE / (gfx_avg * (1024.0*1024.0)),
            (CM55_SIZE * 2) / (cm55_avg * (1024.0*1024.0)), // write then readback the buffer every iteration
            DISP_BYTES_PER_ISSUE / (disp_avg * (1024.0*1024.0)),
            (overlap_total / completed_transfers) * 1000000.0);
    am_util_stdio_printf("\n\n");
    return bTestPass;
} // axi_master_stress_test_cases
